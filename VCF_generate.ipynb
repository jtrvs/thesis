{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc9c1fb-cc0a-4ed4-96ea-7ab84fb3b91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"b5caba36-213a-4245-879f-9a9cb8cc75cd\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "'use strict';\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded(error = null) {\n",
       "    const el = document.getElementById(\"b5caba36-213a-4245-879f-9a9cb8cc75cd\");\n",
       "    if (el != null) {\n",
       "      const html = (() => {\n",
       "        if (typeof root.Bokeh === \"undefined\") {\n",
       "          if (error == null) {\n",
       "            return \"BokehJS is loading ...\";\n",
       "          } else {\n",
       "            return \"BokehJS failed to load.\";\n",
       "          }\n",
       "        } else {\n",
       "          const prefix = `BokehJS ${root.Bokeh.version}`;\n",
       "          if (error == null) {\n",
       "            return `${prefix} successfully loaded.`;\n",
       "          } else {\n",
       "            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n",
       "          }\n",
       "        }\n",
       "      })();\n",
       "      el.innerHTML = html;\n",
       "\n",
       "      if (error != null) {\n",
       "        const wrapper = document.createElement(\"div\");\n",
       "        wrapper.style.overflow = \"auto\";\n",
       "        wrapper.style.height = \"5em\";\n",
       "        wrapper.style.resize = \"vertical\";\n",
       "        const content = document.createElement(\"div\");\n",
       "        content.style.fontFamily = \"monospace\";\n",
       "        content.style.whiteSpace = \"pre-wrap\";\n",
       "        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n",
       "        content.textContent = error.stack ?? error.toString();\n",
       "        wrapper.append(content);\n",
       "        el.append(wrapper);\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(() => display_loaded(error), 100);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.3.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      try {\n",
       "            for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "\n",
       "      } catch (error) {display_loaded(error);throw error;\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"b5caba36-213a-4245-879f-9a9cb8cc75cd\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"b5caba36-213a-4245-879f-9a9cb8cc75cd\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"b5caba36-213a-4245-879f-9a9cb8cc75cd\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hail as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "376a7c55-d386-4ce4-8bd9-227e20e5291c",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.\n: java.io.FileNotFoundException: File file:/tmp/spark-events does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)\n\tat org.apache.spark.deploy.history.EventLogFileWriter.requireLogBaseDirAsDirectory(EventLogFileWriters.scala:77)\n\tat org.apache.spark.deploy.history.SingleEventLogFileWriter.start(EventLogFileWriters.scala:221)\n\tat org.apache.spark.scheduler.EventLoggingListener.start(EventLoggingListener.scala:81)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:632)\n\tat is.hail.backend.spark.SparkBackend$.configureAndCreateSparkContext(SparkBackend.scala:170)\n\tat is.hail.backend.spark.SparkBackend$.apply(SparkBackend.scala:276)\n\tat is.hail.backend.spark.SparkBackend.apply(SparkBackend.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mhl\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-1615>:2\u001b[39m, in \u001b[36minit\u001b[39m\u001b[34m(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory, worker_cores, worker_memory, gcs_requester_pays_configuration, regions, gcs_bucket_allow_list, copy_spark_log_on_error)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/hail/lib/python3.12/site-packages/hail/typecheck/check.py:585\u001b[39m, in \u001b[36m_make_dec.<locals>.wrapper\u001b[39m\u001b[34m(__original_func, *args, **kwargs)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;129m@decorator\u001b[39m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(__original_func: Callable[..., T], *args, **kwargs) -> T:\n\u001b[32m    584\u001b[39m     args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method)\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__original_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/hail/lib/python3.12/site-packages/hail/context.py:389\u001b[39m, in \u001b[36minit\u001b[39m\u001b[34m(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory, worker_cores, worker_memory, gcs_requester_pays_configuration, regions, gcs_bucket_allow_list, copy_spark_log_on_error)\u001b[39m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hail_event_loop().run_until_complete(\n\u001b[32m    370\u001b[39m         init_batch(\n\u001b[32m    371\u001b[39m             log=log,\n\u001b[32m   (...)\u001b[39m\u001b[32m    386\u001b[39m         )\n\u001b[32m    387\u001b[39m     )\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend == \u001b[33m'\u001b[39m\u001b[33mspark\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_spark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43msc\u001b[49m\u001b[43m=\u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapp_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapp_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmin_block_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_block_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbranching_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbranching_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspark_conf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspark_conf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_optimizer_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_optimizer_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_tmpdir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_tmpdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdefault_reference\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_reference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43midempotent\u001b[49m\u001b[43m=\u001b[49m\u001b[43midempotent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mglobal_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mglobal_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip_logging_configuration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_logging_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgcs_requester_pays_configuration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgcs_requester_pays_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy_log_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy_spark_log_on_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend == \u001b[33m'\u001b[39m\u001b[33mlocal\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m init_local(\n\u001b[32m    412\u001b[39m         log=log,\n\u001b[32m    413\u001b[39m         quiet=quiet,\n\u001b[32m   (...)\u001b[39m\u001b[32m    419\u001b[39m         gcs_requester_pays_configuration=gcs_requester_pays_configuration,\n\u001b[32m    420\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-1617>:2\u001b[39m, in \u001b[36minit_spark\u001b[39m\u001b[34m(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, gcs_requester_pays_configuration, copy_log_on_error)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/hail/lib/python3.12/site-packages/hail/typecheck/check.py:585\u001b[39m, in \u001b[36m_make_dec.<locals>.wrapper\u001b[39m\u001b[34m(__original_func, *args, **kwargs)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;129m@decorator\u001b[39m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(__original_func: Callable[..., T], *args, **kwargs) -> T:\n\u001b[32m    584\u001b[39m     args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method)\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__original_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/hail/lib/python3.12/site-packages/hail/context.py:483\u001b[39m, in \u001b[36minit_spark\u001b[39m\u001b[34m(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, gcs_requester_pays_configuration, copy_log_on_error)\u001b[39m\n\u001b[32m    474\u001b[39m app_name = app_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mHail\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    475\u001b[39m (\n\u001b[32m    476\u001b[39m     gcs_requester_pays_project,\n\u001b[32m    477\u001b[39m     gcs_requester_pays_buckets,\n\u001b[32m   (...)\u001b[39m\u001b[32m    481\u001b[39m     )\n\u001b[32m    482\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m backend = \u001b[43mSparkBackend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43midempotent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspark_conf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapp_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_block_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbranching_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtmpdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_tmpdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_logging_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgcs_requester_pays_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgcs_requester_pays_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgcs_requester_pays_buckets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgcs_requester_pays_buckets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy_log_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy_log_on_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend.fs.exists(tmpdir):\n\u001b[32m    504\u001b[39m     backend.fs.mkdir(tmpdir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/hail/lib/python3.12/site-packages/hail/backend/spark_backend.py:130\u001b[39m, in \u001b[36mSparkBackend.__init__\u001b[39m\u001b[34m(self, idempotent, sc, spark_conf, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmpdir, local_tmpdir, skip_logging_configuration, optimizer_iterations, gcs_requester_pays_project, gcs_requester_pays_buckets, copy_log_on_error)\u001b[39m\n\u001b[32m    128\u001b[39m     jhc = hail_package.HailContext.getOrCreate(jbackend, branching_factor, optimizer_iterations)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     jbackend = \u001b[43mhail_package\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSparkBackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapp_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip_logging_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmin_block_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtmpdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_tmpdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgcs_requester_pays_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgcs_requester_pays_buckets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m     jhc = hail_package.HailContext.apply(jbackend, branching_factor, optimizer_iterations)\n\u001b[32m    147\u001b[39m \u001b[38;5;28mself\u001b[39m._jsc = jbackend.sc()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/hail/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/hail/lib/python3.12/site-packages/py4j/protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.\n: java.io.FileNotFoundException: File file:/tmp/spark-events does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)\n\tat org.apache.spark.deploy.history.EventLogFileWriter.requireLogBaseDirAsDirectory(EventLogFileWriters.scala:77)\n\tat org.apache.spark.deploy.history.SingleEventLogFileWriter.start(EventLogFileWriters.scala:221)\n\tat org.apache.spark.scheduler.EventLoggingListener.start(EventLoggingListener.scala:81)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:632)\n\tat is.hail.backend.spark.SparkBackend$.configureAndCreateSparkContext(SparkBackend.scala:170)\n\tat is.hail.backend.spark.SparkBackend$.apply(SparkBackend.scala:276)\n\tat is.hail.backend.spark.SparkBackend.apply(SparkBackend.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n"
     ]
    }
   ],
   "source": [
    "hl.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1af04be-4df2-4d83-baed-b5d20d23e955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysam\n",
      "  Downloading pysam-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Downloading pysam-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (26.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m136.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:06\u001b[0m\n",
      "Installing collected packages: pysam\n",
      "Successfully installed pysam-0.23.0\n"
     ]
    }
   ],
   "source": [
    "! pip install pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e6b5088-40c0-40ab-b62f-ff79e468510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bbaf82-d3fc-41bf-9e90-c126230046fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11063823-6316-4ff5-9d56-bfb43af94abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCF_DIR = '/home/julia/Documents/thesis/vcf_for_generate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07cbf0d8-3635-4227-bbc9-9cd6fa27b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка таблицы с полами\n",
    "sex_info = {\n",
    "    \"000007000020\": \"ж\",\n",
    "    \"000007000030\": \"м\",\n",
    "    \"000007000040\": \"м\",\n",
    "    \"000007000060\": \"м\",\n",
    "    \"000007000070\": \"м\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0126ab0-4f8c-4fd2-9e7c-5e2da9d38636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000007000020', '000007000030', '000007000040', '000007000060', '000007000070']\n"
     ]
    }
   ],
   "source": [
    "old_ids = list(sex_info.keys())\n",
    "print(old_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e534e8-90c0-49fa-9e7e-dcf5da81a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids = [f\"{70000080 + i:012d}\" for i in range(10)]  # 000007000080 ... 000007000179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74186144-19df-40e4-95bb-d4abaec9a2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000070000080', '000070000081', '000070000082', '000070000083', '000070000084', '000070000085', '000070000086', '000070000087', '000070000088', '000070000089']\n"
     ]
    }
   ],
   "source": [
    "print(new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9929c-117e-4fac-a6e6-bdb558fc57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем 10 новых файлов\n",
    "for new_id in new_ids:\n",
    "    # 1. Выбираем случайный исходный образец\n",
    "    original_id = random.choice(old_ids)\n",
    "    original_file = f\"{VCF_DIR + original_id}.vcf.gz\"\n",
    "    sex = sex_info[original_id]  # пол исходного образца\n",
    "    \n",
    "        # 2. Читаем исходный VCF (распаковываем на лету)\n",
    "    with pysam.VariantFile(original_file) as vcf:\n",
    "        # 3. Создаем новый VCF (несжатый)\n",
    "        output_vcf = f\"{VCF_DIR + new_id}.vcf\"\n",
    "        with pysam.VariantFile(output_vcf, \"w\", header=vcf.header) as out:\n",
    "            for record in vcf:\n",
    "                if random.random() > 0.2:  # Удаляем 20% вариантов\n",
    "                    if record.chrom == \"chrX\" and sex == \"м\":\n",
    "                        if random.random() > 0.5:\n",
    "                            out.write(record)\n",
    "                    else:\n",
    "                        out.write(record)\n",
    "            \n",
    "            # 4. Добавляем новые варианты (10% от исходного количества)\n",
    "            for _ in range(int(0.1 * len(list(vcf.fetch())))):\n",
    "                chrom = random.choice([\"chr1\", \"chr2\", \"chr3\", \"chrX\"])\n",
    "                pos = random.randint(1_000_000, 100_000_000)\n",
    "                ref = random.choice([\"A\", \"C\", \"G\", \"T\"])\n",
    "                alt = random.choice([\"A\", \"C\", \"G\", \"T\"])\n",
    "                if ref != alt:\n",
    "                    # record = out.new_record(\n",
    "                    #     contig=chrom, start=pos, stop=pos, ref=ref, alts=[alt],\n",
    "                    #     qual=30, filter=\"PASS\"\n",
    "                    # )\n",
    "                    record = out.new_record(\n",
    "                        contig=chrom,\n",
    "                        start=pos,  # POS в VCF (1-based)\n",
    "                        stop=pos,    # Для однонуклеотидных вариантов = POS\n",
    "                        ref=ref,\n",
    "                        alts=[alt],\n",
    "                        qual=30,     # QUAL (может быть 30, 100 или другое значение)\n",
    "                        filter=\"PASS\",\n",
    "                        info=None      # Обязательное поле INFO (может быть пустым)\n",
    "                    )\n",
    "                    out.write(record)\n",
    "\n",
    "# 5. Обновляем таблицу полов\n",
    "new_sex_info = {\n",
    "    \"ID\": new_ids,\n",
    "    \"sex\": [random.choices([\"м\", \"ж\"], weights=[0.7, 0.3])[0] for _ in range(10)],\n",
    "    \"profile\": [\"WGS\"] * 10\n",
    "}\n",
    "# pd.DataFrame(new_sex_info).to_csv(VCF_DIR + \"/extended_sex_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e54069d8-1a0c-4746-8b24-66364b692c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::hts_idx_load3] The index file is older than the data file: /home/julia/Documents/thesis/vcf_for_generate/000007000030.vcf.gz.tbi\n",
      "[W::hts_idx_load3] The index file is older than the data file: /home/julia/Documents/thesis/vcf_for_generate/000007000060.vcf.gz.tbi\n",
      "[W::hts_idx_load3] The index file is older than the data file: /home/julia/Documents/thesis/vcf_for_generate/000007000070.vcf.gz.tbi\n"
     ]
    }
   ],
   "source": [
    "def generate_synthetic_vcf(original_file, output_file, deletion_rate=0.2, addition_rate=0.1):\n",
    "    original_file = VCF_DIR + original_file + '.vcf.gz'\n",
    "    with pysam.VariantFile(original_file, 'r') as vcf_in:\n",
    "        # Копируем оригинальный заголовок\n",
    "        header = vcf_in.header.copy()\n",
    "        \n",
    "        with pysam.VariantFile(output_file, 'w', header=header) as vcf_out:\n",
    "            # Список для хранения оригинальных вариантов\n",
    "            original_variants = list(vcf_in.fetch())\n",
    "            \n",
    "            # Фильтрация и сохранение вариантов\n",
    "            for record in original_variants:\n",
    "                # Пропускаем варианты с вероятностью deletion_rate\n",
    "                if random.random() > deletion_rate:\n",
    "                    vcf_out.write(record)\n",
    "            \n",
    "            # Добавление новых случайных вариантов\n",
    "            new_variants_count = int(len(original_variants) * addition_rate)\n",
    "            for _ in range(new_variants_count):\n",
    "                # Создание нового варианта\n",
    "                new_record = vcf_out.new_record()\n",
    "                \n",
    "                # Случайный выбор хромосомы\n",
    "                chromosomes = list(header.contigs.keys())\n",
    "                new_record.chrom = random.choice(chromosomes)\n",
    "                \n",
    "                # Случайная позиция\n",
    "                new_record.pos = random.randint(1, header.contigs[new_record.chrom].length)\n",
    "                \n",
    "                # Случайные ref и alt аллели\n",
    "                bases = ['A', 'C', 'G', 'T']\n",
    "                new_record.ref = random.choice(bases)\n",
    "                alt_bases = [base for base in bases if base != new_record.ref]\n",
    "                new_record.alts = (random.choice(alt_bases),)\n",
    "                \n",
    "                # Установка качества\n",
    "                new_record.qual = random.uniform(10, 100)\n",
    "                \n",
    "                # Добавление фильтра\n",
    "                new_record.filter.add('PASS')\n",
    "                \n",
    "                vcf_out.write(new_record)\n",
    "\n",
    "# Пример использования\n",
    "def generate_synthetic_vcfs(input_files, output_dir, new_ids):\n",
    "    for new_id, input_file in zip(new_ids, input_files):\n",
    "        output_file = f\"{output_dir}/{new_id}.vcf\"\n",
    "        generate_synthetic_vcf(input_file, output_file)\n",
    "\n",
    "# Пример вызова\n",
    "input_files = old_ids\n",
    "n_ids = ['000070000085', '000070000086', '000070000087', '000070000088', '000070000089']\n",
    "generate_synthetic_vcfs(input_files, VCF_DIR, n_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d17baba-5fe2-4d77-9e5c-e4abf1eed194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000070000080', '000070000081', '000070000082', '000070000083', '000070000084', '000070000085', '000070000086', '000070000087', '000070000088', '000070000089']\n"
     ]
    }
   ],
   "source": [
    "print(new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb155f-0e94-4828-bb88-5d67c6b48a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Обновляем таблицу полов\n",
    "new_sex_info = {\n",
    "    \"ID\": new_ids,\n",
    "    \"sex\": [random.choices([\"м\", \"ж\"], weights=[0.7, 0.3])[0] for _ in range(10)],\n",
    "    \"profile\": [\"WGS\"] * 10\n",
    "}\n",
    "pd.DataFrame(new_sex_info).to_csv(VCF_DIR + \"/extended_sex_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36c25316-6617-4789-9418-2f5bd0c56021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_vcf_v2(original_file, output_file, deletion_rate=0.2, addition_rate=0.1):\n",
    "    original_file = VCF_DIR + original_file + '.vcf.gz'\n",
    "    with pysam.VariantFile(original_file, 'r') as vcf_in:\n",
    "        header = vcf_in.header.copy()\n",
    "        \n",
    "        # Определяем стандартные хромосомы\n",
    "        standard_chromosomes = [f'chr{i}' for i in range(1, 23)] + ['chrX', 'chrY']\n",
    "        \n",
    "        with pysam.VariantFile(output_file, 'w', header=header) as vcf_out:\n",
    "            original_variants = list(vcf_in.fetch())\n",
    "            \n",
    "            for record in original_variants:\n",
    "                if random.random() > deletion_rate:\n",
    "                    # Заменяем имя хромосомы на стандартное\n",
    "                    chrom = record.chrom.split('_')[0]  # Берем часть до первого _\n",
    "                    if chrom in standard_chromosomes:\n",
    "                        record.chrom = chrom\n",
    "                        vcf_out.write(record)\n",
    "            \n",
    "            new_variants_count = int(len(original_variants) * addition_rate)\n",
    "            for _ in range(new_variants_count):\n",
    "                new_record = vcf_out.new_record()\n",
    "                new_record.chrom = random.choice(standard_chromosomes)  # Только стандартные\n",
    "                new_record.pos = random.randint(1, 100_000_000)  # Фиксированный диапазон\n",
    "                \n",
    "                bases = ['A', 'C', 'G', 'T']\n",
    "                new_record.ref = random.choice(bases)\n",
    "                new_record.alts = (random.choice([b for b in bases if b != new_record.ref]),)\n",
    "                \n",
    "                new_record.qual = random.uniform(10, 100)\n",
    "                new_record.filter.add('PASS')\n",
    "                \n",
    "                vcf_out.write(new_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b7ae669-4eeb-490b-9748-fc0175874461",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ids = ['000070000080', '000070000081', '000070000082', '000070000083', '000070000084', '000070000085', '000070000086', '000070000087', '000070000088', '000070000089', '000070000089']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d693b30d-493b-485d-9a1d-023739385c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_vcfs2(input_files, output_dir, new_ids):\n",
    "    for new_id, input_file in zip(new_ids, input_files):\n",
    "        output_file = f\"{output_dir}/{new_id}.vcf\"\n",
    "        generate_synthetic_vcf_v2(input_file, output_file)\n",
    "\n",
    "input_files = old_ids\n",
    "generate_synthetic_vcfs2(input_files, VCF_DIR, n_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5ce1669-479d-4002-a433-fa46f544a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': ['000070000080', '000070000081', '000070000082', '000070000083', '000070000084', '000070000085', '000070000086', '000070000087', '000070000088', '000070000089', '000070000089'], 'sex': ['ж', 'м', 'м', 'ж', 'м', 'ж', 'м', 'м', 'ж', 'м', 'ж'], 'profile': ['WGS', 'WGS', 'WGS', 'WGS', 'WGS', 'WGS', 'WGS', 'WGS', 'WGS', 'WGS', 'WGS']}\n"
     ]
    }
   ],
   "source": [
    "# 5. Обновляем таблицу полов\n",
    "new_sex_info = {\n",
    "    \"ID\": n_ids,\n",
    "    \"sex\": [random.choices([\"м\", \"ж\"], weights=[0.7, 0.3])[0] for _ in range(11)],\n",
    "    \"profile\": [\"WGS\"] * 11\n",
    "}\n",
    "pd.DataFrame(new_sex_info).to_csv(VCF_DIR + \"extended_sex_info.csv\", index=False)\n",
    "print(new_sex_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ed0490c-9eb5-4cc1-a677-1d3c09778fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(n_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7160158-32d8-4e5b-9f7e-71c0682d3d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
